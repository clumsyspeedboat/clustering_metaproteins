{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689b3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.spatial.distance import pdist\n",
    "import networkx as nx\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams, cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c2f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_and_pca_from_df(df):\n",
    "    '''\n",
    "    Function processes the data using Principal component analysis(PCA)\n",
    "    Args:\n",
    "        df : Dataframe \n",
    "    Returns dataframe containing rincipal component of df\n",
    "    '''\n",
    "    \n",
    "    df_normalized = pd.DataFrame()\n",
    "    cols = list(df.columns)\n",
    "    df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
    "    \n",
    "    df_pca = pd.DataFrame(PCA(n_components = 2).fit_transform(df_normalized))\n",
    "    df_pca.columns = ['P1', 'P2']\n",
    "    df_pca.index = df.index\n",
    "    \n",
    "    return df_normalized, df_pca\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "def calculate_eigen_self_tuning(df, k):\n",
    "    \n",
    "    dimension = df.shape[0]\n",
    "    dist_ = pdist(df)\n",
    "    pd = np.zeros([dimension, dimension])\n",
    "    dist = iter(dist_)\n",
    "    for i in range(dimension):\n",
    "        for j in range(i+1, dimension):  \n",
    "            d = next(dist)\n",
    "            pd[i,j] = d\n",
    "            pd[j,i] = d\n",
    "            \n",
    "    #calculate local sigma\n",
    "    sigmas = np.zeros(dimension)\n",
    "    for i in tqdm(range(len(pd))):\n",
    "        sigmas[i] = sorted(pd[i])[7]\n",
    "    \n",
    "    adjacency_matrix = np.zeros([dimension, dimension])\n",
    "    dist = iter(dist_)\n",
    "    for i in tqdm(range(dimension)):\n",
    "        for j in range(i+1, dimension):  \n",
    "            d = np.exp(-1*next(dist)**2/(sigmas[i]*sigmas[j]))\n",
    "            adjacency_matrix[i,j] = d\n",
    "            adjacency_matrix[j,i] = d\n",
    "            \n",
    "    degree_matrix = np.sum(adjacency_matrix, axis=0) * np.eye(dimension)\n",
    "    \n",
    "    # Normalized laplacian matrix\n",
    "    d_half = linalg.fractional_matrix_power(degree_matrix, -0.5)\n",
    "    laplacian_matrix_normalized = np.matmul(np.matmul(d_half, adjacency_matrix), d_half)\n",
    "    \n",
    "    e, v = np.linalg.eigh(laplacian_matrix_normalized)\n",
    "    X = v[:, -1*k:]\n",
    "    \n",
    "    row_sums = X.sum(axis=1)\n",
    "    Y = X / row_sums[:, np.newaxis]\n",
    "            \n",
    "    return X, Y\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def ensemble_classification(df, test_index_list, class_label_list,n):\n",
    "    \n",
    "    df['class_label'] = class_label_list\n",
    "    \n",
    "    train_df = df.loc[~ df.index.isin(test_index_list)]\n",
    "    test_df = df.loc[df.index.isin(test_index_list)]\n",
    "\n",
    "    X_train = train_df.drop(['class_label'],axis=1)\n",
    "    y_train = train_df[['class_label']]\n",
    "\n",
    "    X_test = test_df.drop(['class_label'],axis=1)\n",
    "    y_test = test_df[['class_label']]\n",
    "    \n",
    "    acc_1 = [] \n",
    "    mcc_1 = []\n",
    "    acc_2 = []\n",
    "    mcc_2 = []\n",
    "    acc_3 = []\n",
    "    mcc_3 = []\n",
    "    \n",
    "    for values in range(0,n+1):\n",
    "        \n",
    "        classifier0 = NearestCentroid()\n",
    "        classifier0.fit(X_train, y_train.values.ravel())\n",
    "        acc_1.append(classifier0.score(X_test, y_test))\n",
    "        mcc_1.append(mcc(classifier0.predict(X_test), y_test))\n",
    "        \n",
    "        classifier1 = KNeighborsClassifier(n_neighbors=5)\n",
    "        classifier1.fit(X_train, y_train.values.ravel())\n",
    "        acc_2.append(classifier1.score(X_test, y_test))\n",
    "        mcc_2.append(mcc(classifier1.predict(X_test), y_test))\n",
    "        \n",
    "        classifier2 = DecisionTreeClassifier(criterion = \"gini\")\n",
    "        classifier2.fit(X_train, y_train)\n",
    "        acc_3.append(classifier2.score(X_test, y_test))\n",
    "        mcc_3.append(mcc(classifier2.predict(X_test), y_test))\n",
    "        \n",
    "    print('Nearest Centroid (acc, mcc) -',sum(acc_1)/len(acc_1), sum(mcc_1)/len(mcc_1))\n",
    "    print('K nearest neighbours (acc, mcc) -',sum(acc_2)/len(acc_2),sum(mcc_2)/len(mcc_2) )\n",
    "    print('Decision Tree (acc, mcc) -',sum(acc_3)/len(acc_3),sum(mcc_3)/len(mcc_3) )\n",
    "    \n",
    "    \n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30279338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset 1\n",
    "df_csv_data = pd.read_csv(\"dataset_1/d1_mp.csv\", index_col = 0)\n",
    "df_normalized, df_pca = norm_and_pca_from_df(df_csv_data)\n",
    "\n",
    "df_pca['class_label'] = ['CD' if 'CD' in index \n",
    "                         else 'IBS' if 'IBS' in  index\n",
    "                         else 'UCr' if 'UCr' in index \n",
    "                         else 'UCa' if 'UCa' in index \n",
    "                         else 'GCA' if 'GCA' in index \n",
    "                         else 'A' if 'C' not in index else 'C' \n",
    "                         for index, patient in df_pca.iterrows()]\n",
    "df_pca['class_label'] = df_pca['class_label'].astype('category').cat.codes\n",
    "\n",
    "df_pca_control = df_pca[['P1','P2','P3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset 2\n",
    "df_csv_data = pd.read_csv(\"dataset_2/d2_mp.csv\", index_col=0)\n",
    "# df_csv_data = df_csv_data.iloc[:, 0:12649]\n",
    "\n",
    "df_csv_data2 = df_csv_data.loc[:,(df_csv_data.mean() >= 0.5)]\n",
    "df_normalized, df_pca = norm_and_pca_from_df(df_csv_data)\n",
    "\n",
    "df_pca['class_label'] = ['C' if 'C' in index else 'N' if 'N' in index else 'H' for index, patient in df_pca.iterrows()]\n",
    "df_pca['class_label'] = df_pca['class_label'].astype('category').cat.codes\n",
    "df_pca_control = df_pca[['P1','P2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa03ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n",
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_16676\\1843745508.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_normalized[cols] = pd.DataFrame(normalize(StandardScaler().fit_transform(df[cols])))\n"
     ]
    }
   ],
   "source": [
    "## Load combined dataset\n",
    "df_csv = pd.read_csv(\"d3_mp.csv\", index_col=0)\n",
    "df_csv_data = df_csv.iloc[:, 0:170]\n",
    "\n",
    "df_normalized, df_pca = norm_and_pca_from_df(df_csv_data)\n",
    "\n",
    "df_pca['class_label'] = ['N' if 'N' in index\n",
    "                         else 'H' if 'H' in index\n",
    "                         else 'CD' if 'CD' in index \n",
    "                         else 'IBS' if 'IBS' in  index\n",
    "                         else 'UCr' if 'UCr' in index \n",
    "                         else 'UCa' if 'UCa' in index\n",
    "                         else 'GCA' if 'GCA' in index \n",
    "                         else 'A' if '_A' in index else 'C' \n",
    "                         for index, patient in df_pca.iterrows()]\n",
    "\n",
    "df_pca['class_label'] = df_pca['class_label'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.class_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609c8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list = ['P13_C','P14_C','P15_C','P16_C','P17_C',\n",
    "#               'P25_CD','P26_CD','P27_CD',\n",
    "#               'P34_UCr',\n",
    "#               'P41_UCa', 'P42_UCa',\n",
    "#               'P52_IBS', 'P53_IBS', 'P54_IBS','P55_IBS',\n",
    "#               'P62_A', 'P63_A',\n",
    "#               'P70_GCA', 'P71_GCA']\n",
    "\n",
    "# index_list = ['C_15','C_16','C_17','C_18','C_19',\n",
    "#               'N_44','N_45','N_46','N_47','N_48','N_49','N_50','N_51',\n",
    "#               'H_74','H_75','H_76','H_77','H_78','H_79','H_80']\n",
    "\n",
    "index_list = ['P13_C','P14_C','P15_C','P16_C','P17_C',\n",
    "              'P25_CD','P26_CD','P27_CD',\n",
    "              'P34_UCr',\n",
    "              'P41_UCa', 'P42_UCa',\n",
    "              'P52_IBS', 'P53_IBS', 'P54_IBS','P55_IBS',\n",
    "              'P62_A', 'P63_A',\n",
    "              'P70_GCA', 'P71_GCA',\n",
    "              'C_15','C_16','C_17','C_18','C_19',\n",
    "              'N_44','N_45','N_46','N_47','N_48','N_49','N_50','N_51',\n",
    "              'H_74','H_75','H_76','H_77','H_78','H_79','H_80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_classification(df_csv_data, index_list, df_pca.class_label, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.index = df_csv_data.index\n",
    "ensemble_classification(df_normalized, index_list, df_pca.class_label, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7928dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 9787.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 2335.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Centroid (acc, mcc) - 0.3076923076923077 0.20089040639258376\n",
      "K nearest neighbours (acc, mcc) - 0.5128205128205128 0.4056977078868017\n",
      "Decision Tree (acc, mcc) - 0.3961952026468157 0.2759428597136052\n"
     ]
    }
   ],
   "source": [
    "Xst, Yst = calculate_eigen_self_tuning(df_normalized, 18)\n",
    "df_U = pd.DataFrame(Xst)\n",
    "df_N = pd.DataFrame(Yst)\n",
    "\n",
    "df_U.index = df_csv_data.index\n",
    "ensemble_classification(df_U, index_list, df_pca.class_label, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.class_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860395eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b73108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e54d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
